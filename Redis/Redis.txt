Nosql（Not only sql）

为什么使用Nosql
    单机mysql（网站访问量不大，静态网页）
        瓶颈：数据量总大小一个机器放不下；索引内存放不下；读写混合一个实例不能承受
    Memcached（缓存）+Mysql+垂直拆分
        通过缓存技术缓解数据库的压力，优化数据的索引和结构
        瓶颈：多个web机器的缓存不能共享，大量小文件带来IO压力
    Mysql主从读写分离
        Memcached（缓存）只能缓解读压力，读写集中在一个数据库压力大。
        通过主从复制技术达到读写分离。主库负责写，从库负责读。从库快速从主库更新
        瓶颈：主库的写压力；数据量持续增加，MyISAM使用表锁，在高并发下产生了严重的锁问题
    分库分表+水平拆分+mysql集群
        使用InnoDB引擎
        分区分表：
            紧耦合的放在一个库，边缘数据放在另一个库；
            表拆分
        mysql集群
        瓶颈：
            存储大本文导致数据库表非常大，数据库恢复很慢；
            mysql的扩展性差，大数据下IO压力大，表结构更改困难

    结论：传统关系型数据库不适合目前目前的状况

Nosql是什么
    泛指非关系型数据库。
    这些类型的数据库不需要固定的存储模式，无需多余操作就可以横向扩展

Nosql能做什么
    数据扩展
        数据之间无关系，非常容易扩展（在架构层面带来了可扩展的能力）
    大数据量高性能
        Mysql使用Query cache，每次表更新Cache就失效，是一种大粒度的Cache
        Nosql纪录级的，是一种细粒度的Cache，更适合web2.0的交互频繁的应用
    灵活的数据模型
        Mysql增删字段非常麻烦
    传统的RDNMS（关系型数据库）VS NOSQL
        RDBMS
            高度组织化结构化的数据
            结构化查询语言（SQL）
            数据和关系都存储在单独的表中
            数据操纵语言，数据定义语言
            严格一致性
            基础事务
        Nosql
            不仅仅是Sql
            没有声明性查询语言
            没有预定义模式
            键值对存储（json格式存储），列存储，文档存储，图形数据库
            最终一致性，而非ACID属性
            非结构化和不可预知的数据
            CAP定理
            高性能，高可用和可伸缩性

Nosql对比
    Memcache：专业的高速缓存（功能较少）
    Redis：一专多能（快，读写性能极佳），数据类型丰富，定位是做缓存，通过键值对存储，内存型KV系统（不支持索引）
    Mongodb（分布式文件存储数据库）：定位是高性能文档型数据库（读写能力不如Redis），功能灵活（很像，但是无法取代关系型数据库），支持二级索引
    HBase：列数据库，适用于大数据场景（分布式文件系统）（写多读少）（读写能力不如Redis）。和Hadoop无缝集成。

互联网环境的3V+3高
    大数据时代的3V：海量（Volume），多样（Variety），实时（Velocity）
    互联网需求的三高：高并发，高可扩，高性能（高可用）

经典应用
    当下的应用是sql和nosql一起使用
    互联网应用的难点
        数据类型多样性
        数据源多样性和变化重构
        数据源改造而数据服务平台不需要大面积重构
    解决办法
        阿里统一数据服务层：UDSL（映射，API，热点缓存等）


nosql使用聚合模型
    原因：
        高并发的操作不建议使用关联查询
        互联网公司用冗余数据来避免关联查询
        分布式事务支持不了太多的并发  
    聚合模型：
        KV键值
        Bson（Binary JSON）
        列族（适用于压缩数据）
        图形

Nosql数据库的四大分类
    KV键值：
        应用场景：内容缓存，大量数据的高负载访问，也用于一些日志系统
        数据模型：键值对，通常使用HashTable
        优点：速度快
        缺点：只能通过key访问，数据无结构化，通常被当作字符串或者二进制数据
        举例：Redis，Oracle BDB
    文档型数据库（bson格式较多）：
        应用场景：web应用（与KV类似，区别在于value有结构，而且数据库可以理解value的内容）
        数据模型：KV键值对，Value为数据化结构（可以使用二级索引）
        优点：数据结构要求不言而，表结构可变，不需要像关系型数据库一样预先定义表的结构
        缺点：查询性能不高，且缺乏统一的查询语法
        举例：MongoDB（最像关系型数据库），CouchDB
    列存储数据库（分布式大数据）：
        应用场景：分布式的文件系统（云环境）
        数据模型：以列簇形式存储，将同一列数据存在一起
        优点：查找速度快，可扩展性强，更易进行分布式扩展
        缺点：功能相对局限
        举例：HBase，Cassandra
    图关系数据库（不是存放图形，存放的是（多对多）关系）：
        应用场景：社交网络，推荐系统等，专注于构建关系图谱
        数据模型：图结构
        优点：利用图结构算法（例如最短路径）
        缺点：很多时候需要做全图计算
        举例：Neo4J，InfoGrid

CAP+BASE
    传统的ACID
        原子性（Atomicity），一致性（Consistency），隔离性（Isolation），持久性（Durability）
    CAP
        强一致性（Consistency），高可用性（Availability），分区容错性（Partition tolerance）
    CAP的三进二
        一个分布式系统不可能同时很好的满足CAP，最多只能同时较好的满足两个  
        CA：单点集群，满足一致性和可用性，但是可扩展性不强 （传统关系型数据库）
        CP：满足一致性和分区容错性，但是性能不高 （MongoDB，HBase，Redis）
        AP：满足可用性和分区容错性，但是对一致性要求较低 （CouchDB）（大部分的网站架构的选择，高并发很难保证强一致性，同时不可用的代价太高）

        nosql一定要实现分区容错性，所以是在AC之间做取舍
        什么时候选一致性（Consistency）： 
        什么时候选高可用（Availability）：对实时系统要求并不严格（读写的实时性可以不是特别好，秒级的延时是允许的），允许实现最终一致性。

    BASE
        基本可用（Basically Available）
        软状态（Soft state）
        最终一致（Eventually consistent）
        BASE是为了解决数据库强一致性引起的可用性降低问题
        思想是让系统放松某一时刻对数据一致性的要求来换取系统整体伸缩性和性能上的改观

    分布式+集群
        分布式：不同的多台服务器部署不同的功能（通过RPC/PMI通信和互相调用），对外提供服务和组内协作
        集群：不同的多台服务器部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问

Redis入门介绍
    是什么 
        Redis：REmote DIctionary Server（远程字典服务器）
        高性能的（key/value）分布式内存数据库，基于内存运行
        也支持持久化
        被称为数据结构服务器
        与其他kv产相比有三个特点
            Redis支持数据持久化
            除了KV以外，还支持list,set,zset和hash等数据结构
            支持主从模式的数据备份
    
    能干什么
        内存存储和持久化，支持异步将内存数据写入磁盘，同时不影响继续服务
        取最新N个数据的操作（List集合）
        模拟类似于HeetpSeesion这种需要设定过期时间的功能
        发布、订阅消息系统（可以作为消息中间件）
        定时器，计数器

    怎么用
        数据类型、基本操作和配置
        持久化和复制，RDB/AOF
        复制
    
Redis杂项基础
    单进程（为什么）
        单进程处理对客户端的请求
        对读写时间的响应是是通过对Linux的epoll函数包装得来的
        Redis的数级处理速度完全依赖主进程的执行效率
            epoll是Linux内核为了处理大批量文件描述符二做了改进的，是linux下多路复用IO接口select/poll的增强版本，能显著提高在大量并发连接中只有少量活跃的情况下的系统CPU利用率
    默认16个数据库，类似数组从0号下标开始，默认初始使用0号
        myredis.conf文件中database有默认值
    Select命令切换数据库
        select n（切换到n，默认0~15）
    Dbsize查看当前数据库Key的数量
    FlushDB清空当前库
    Flushall清除全部数据库
    统一密码管理：要么都ok要么都连不上
    索引都是从0开始
    默认端口是6379

Redis数据类型
    常用五大数据类型：String，list，hash，set，zset（Sorted set，有序集合）
    其他数据类型：Bit arrays，HyperLogLogs
    String
        redis的基本类型，和Memcached一样的数据类型，一个key对应一个value
        string类型是二进制安全的。（意思是redis中的string类型可以包含任何数据，比如图片或者序列化对象）    
        string类型是最基本的数据类型，redis中一个string最多可以512M
    Hash（类似java中的map<String,Object>）
        是一个键值对集合
        一个string类型的field和一个value的映射表，hash特别适合存储对象
    List 
        底层是LinkedList，是个链表
        按照插入顺序排序，可以添加一个元素在列表头部（头插法）或尾部（尾插法）
    Set 
        是String类型的无序无重复集合
        通过HashTable实现
    Zset
        String类型的有序无重复的集合
        每个String元素会关联一个double类型的分数
        按照分数从小到大排序
        成员是唯一的（String不可重复），但是分数可以
    
常见数据类型的操作命令
    redisdoc.com

    key键
        DBsize ：查看当前数据库中key的个数
        keys *：查看当前库中所有的key（不返回值，只返回key）
        set k1 v1：创建（覆盖）键值对
        EXISTS k1：判断是否存在k1这个键
        get k1:范围k1对应的value
        move k2 2：把k2移动到数据库2
        ttl k1：查看k1的剩余存活时间，如果为负数代表已过期，会从内存中移除（此时get *中不返回k1，get k1会返回nil）
        EXPIRE k3：设定k3的剩余存活时间为10秒
        del k1：删除指定的KV
        type k1：查看value的数据类型

    String字符串（单值多value）
        append k1 12345：在k1的值v1（v1是字符串）后面附加给定的字符串，返回结果的长度
        如果value可以直接转变为整数，例如v1 = "1"
            incr k1 ：k1对应的值数字+1（此时v1变成"2"）
            decr k1 ：k1对应的值数字-1
            incrby k1 n ：k1对应的值数字+n 
            decrby k1 n ：k1对应的值数字-n
        getrange k1 n m ：相当于v1.subString(n,m+1)（下标为m的也要）
        setrange k1 n "XXXXX"：从下标n开始，把后面的5位用字符串“XXXXX”覆盖。前后的其他内容不动 
        setnx k1 xxxxx：如果k1不存在，则添加kv，k是k1，v是xxxxx字符串。如果k1已经存在则不做操作，返回0
        setex k1 time xxxxx：带过期时间的set，过期时间为time，单位是秒
        mget,mset,msetnx ：批量设置/读取，（如果msetnx中有一个失效了，那么全部都失效）

    List列表（链表）（单值多value）
        lpush list01 1 2 3 4 5：从左侧插入12345，类似于链表头插法，里面实际顺序是54321
        rpush list02 1 2 3 4 5：从右侧插入，实际存放顺序和插入顺序相同
        lrange list01 0 3：从左侧输出，5432
        lpop list01：输出最左侧的一个元素（并且从list中去掉这个元素）
        rpop list01：输出最右侧的一个元素
        lindex list01 2：返回（从左数）下标为2的元素
        llen list01：返回元素个数
        lrem list01 n v：删除n个值为v的
        ltrim list01 n m：截取并保留下标n到m（两头都包括）的部分元素，其他元素删除
        rpoplpush list01 list02：从list01右侧取出一个元素，从左侧插入到list02中（头插法），其实相当于把list01最后一个元素取出放到list02最前面
        lset list01 n "x"：把下标为n的元素设为x
        linsert list01 before n "y"：把”y“插入下标y之前

    set集合（单值多value）
        sadd set01 1 1 3 ：向集合中添加元素，会自动去重
        smembers set01：输出集合中的元素 
        sismember set01 n：查看n是否是set01中的元素
        scad set01：获取集合中的元素个数   
        srem set01 n：删除集合中的元素n
        srandamember set01 3：从集合中随机抽取3个元素
        spop set01：随机出栈一个元素
        smove set01 set02 n：把set01中的元素n移动到set02中
        sdiff set01 set02：差集
        sinter set01 set02：交集
        sunion set01 set02：并集

    Hash哈希（依然是KV模式，一个K可以对应多个V，并且每个V自身也是一个键值对）
        hset hash01 k1 v1：添加一对键值对到hash01中（键值对本身作为一个value）
        hget hash01 k1：通过hash01和k1共同取得k1对应的value
        hmset hash01 k2 v2 k3 v3：同时向hash01中导入多组KV
        hgetall hash01：获取hash01中的所有键值对
        hdel hash01 k1：删除指定的KV
        hlen hash01：返回键值对的个数
        hexists hash01 k2：判断某个键是否存在
        hkeys hash01：获取全部的value中的键
        hvals hash01：获取全部value中的value
        hincrby hash01 k1 n：k1对应的value在数值上增加n（如果该值（字符串）无法转变为整型则报错）
        hincrby hash01 k2 m：k1对应的value在数值上增加一个浮点数
        hsetnx hash01 k1 v1：不存在则添加
        
Zset有序集合


redis配置文件解析（Linux开发中，配置大于编码）
     
redis的持久化 
    RDB （Redis DataBase）
        是什么
            在指定的时间间隔内将内存中的数据集快照写入磁盘（Snapshot快照）
            恢复时将快照文件直接读到内存中
            redis会单独创建（fork）一个子进程来进行持久化，子进程会将数据写入到一个临时文件中，待持久化过程结束了，再用这个临时文件替换上次的持久化文件。
            fork子进程的时候使用到了copy on write（写时复制，COW技术）
                关于COW技术：
            整个过程中主进程不进行任何IO，因此保证了性能。
            RDB的缺点是最后一次持久化后的数据可能丢失
            如果需要大规模的数据恢复，且对数据完整性不是特别敏感，那么RDB会比AOF更高效。
        Fork
            复制一个与当前进程一样的进程，新进程的所有数据（遍历环境遍历，程序计数器等）都和原变量一致，但是是一个全新的进程，并且作为原进程的子进程。
        RDB保存的是dump.rdb文件
            配置：save <seconds> <changes>，配置多少秒内，发生了多少次（修改，删除，写）操作，就进行持久化，生成dunp.rdb文件
                默认：15分钟内改1次，5分钟内改10次，1分钟内改10000次
                禁用： save "" 传一个工资发串作为参数就会禁用此功能
            立刻自动保存（比如当前输入的数据非常重要）：
                save （不加参数），优先完成保存，其他全部阻塞
                bgsave在后台一步进行快照操作，同时还可以响应客户端请求
                使用flushall命令也会产生dump.rdb文件，但是是空的，毫无意义
            可以通过lastsave命令获取最近一次成功执行快照的时间
            dump文件 需要使用冷拷贝（拷贝到其他的机器上）
        如何恢复
            将备份文件（dump.rdb）移动到redis安装目录并且启动服务即可
        优势
            适合大规模数据恢复
            对数据完整性和一致性要求不高
        劣势
            最后一次快照可能丢失
            fork时候内存中数据复制，性能受损

        RDB总结
            RDB是一个非常紧凑的文件
            在保存RDB文件的时候，父进程唯一的任务就是fork一个子进程，其他所有任务全部交给子进程，因此可以最大化redis的性能
            与AOF相比，在恢复大的数据集的时候，RDB更快

            数据丢失风险大
            RDB需要经常fork子进程来保存数据集到硬盘上。如果数据集比较大，fork可能比较耗时，会产生毫秒级的响应延时

AOF（Append Only File）
    （）RDB会丢失最后一次持久化的数据

    是什么    
        以日志的形式记录每个写操作，将Redis执行过的所有写指令记下来，只允许追加文件但是不允许修改文件，redis启动之初会读取文件重构数据
        redis重启就根据日志文件的内容将写指令从前到后执行一次完成数据的恢复工作
    
    AOF保存的是appendonly.aof文件
    dump文件和aof文件可以同时共存，加载时先加载aof文件
    aof文件损坏（可能是因为事故，网络等原因）修复：redis-check-aof --fix appendonly.aof
    aof配置策略
        appendonly 默认是no，不使用aof
        appendfsync：
            always：同步持久化，每次发生数据变化会立刻记录，性能较差但是数据完整性较好
            Everysec：出厂默认推荐，异步操作，每秒操作，如果一秒内宕机可能会损失一定的数据
            no 

    rewrite（重写机制）
        是什么：
            aof采用文件追加方式，文件会越来越大，为了避免此类情况，增加了重写机制
            当aof文件大小超过指定阈值的时候，redis会启动aof文件压缩
            只保留可以恢复数据的最小指令集，可以使用命令bgrewriteaof
        重写原理
            aof文件持续增长而过大时，会fork出来一条新进程将文件重写（先写临时文件然后rename），遍历新进程中的内存数据，对每条数据记录一个set语句
            重写aof文件没用读取旧的aof，而是将整个数据库内容用命令的方式重写了一个新的aof文件（忽略数据的具体创建流程，只要得到同样的结果就行）
        触发机制
            redis会记录上一次重写时的aof大小
            默认配置是当aof文件大小是上一次rewrite后大小的一倍且文件大于64M时触发

        No-appendonly-on-rewrite：重写时是否可以运用Appendfsync，默认是no
        Auto-aof-rewrite-min-size：设置重写的基准值
        Auto-rewrite-percentage：设置重写的基准值

    优势
        每次修改同步：appendfsync always 同步持久化，每次变化立即记录 性能较差但是安全性高
        每秒同步：appendfsync everysec 异步同步，每秒记录 如果一秒内宕机会有数据丢失
        不同步：appendfsync no 不同步 
    劣势
        相同数据集下aof远大于rdb文件，恢复速度慢
        运行效率要低于aof，每秒同步的时候效率要好，不同步的时候效率等同rdb

    aof总结
        aof文件是一个只进行追加的日志文件
        redis回在aof文件体积过大时进行文件重写
        aof文件（以redis协议的格式）保存了所有对数据库执行的写入操作，因此可读性好，文件分析轻松

        相同数据集的情况下，aof文件体积大于rdb
        根据所使用的fsync策略，aof的速度可能会慢于rdb

官网建议
    rdb持久化方式可以在指定的时间间隔对数据进行快照存储
    aof持久化方式记录每次对服务器进行的读写，每次重启服务器的时候重新执行命令
    redis能对aof文件进行后台重写，使得aof文件的体积不至于过大
    只做缓存：如果redis只作为缓存，可以不适用持久化
    如果同时开启了两种持久化方式
        优先载入aof文件（因为aof文件数据集一般更完整）
        rdb不实时，但是更适合作为备份数据库（aof不断变化不好备份）
        快速重启时使用rdb，而且不会有aof的潜在bug
    性能建议
        rdb只作为后备，因此建议只在slave节点使用，而且只需要15分钟备份一次
        如果使用了aof
            好处是最坏情况丢失两秒的数据
            代价是持续的io
            rewrite过程种带来的阻塞几乎不可避免，如果硬盘许可，应该尽量减少rewrite的次数，比如增大重写默认值
        如果不适用aof，仅依靠master-slave架构也可以实现高可用性
            可以节省io，也节省rewrite带来的系统波动
            代价是如果master-slaver同时崩溃会导致十几分钟的数据损失
            启动脚本需要比较主从节点的rdb文件，载入新的那个（新浪微博使用的架构）

redis事务
    本质是一组命令的集合，所有命令都会序列化，按顺序串行化执行而不会被其他命令插入
    作用：在一个队列中一次性、顺序的、排他性的执行一系列命令
    如何使用
        正常执行：MULTI开启事务，EXEC提交命令
        放弃事务：DISCARD放弃事务
        全体连坐：如果事务中一条指令（加入队列时）失败，那么整个事务失败
        冤头债主：如果事务中一条指令加入队列时成功，但是真正执行时失败，那么事务中其他指令依然能够执行
        watch监控：
            （非常重要）乐观锁/悲观锁/CAS（check and set）
                悲观锁：每次操作前先上锁，防止冲突的发生（安全，适用于写频繁的操作，但是效率低）
                乐观锁：假设不存在冲突，先进行操作，如果发现了版本号不一致，再重新操作（适合多读的操作，有利于高并发）
                CAS：
            使用watch监视一个（或多个key），如果在事务执行过程中监视的key被其他命令所改动，那么事务将被打断
            unwatch：取消对所有key的监控
    事务的三阶段
        开启：MUTLI
        入队：将多个命令加入到事务执行队列（而不是立即执行），如果在入队过程中出错，则整个事务失败；如果入队过程无误但是实际执行出错，那么事务中其他命令可以正常执行
        执行：EXEC  
    事务的三特性
        单独的隔离操作：所有命令序列化，按顺序执行，在执行过程中不会被客户端的命令请求打断
        没用隔离级别的概念：提交之前命令只是进入队列，不会真正执行，因此不会出现幻读脏读等问题
        不保证原子性：如果有一条命令执行失败（成功进入事务队列），其他的命令仍会执行，没有回滚

redis的发布和订阅
    是什么
        进程间的一种通信模式：发送者发送（pub）消息，订阅者（sub）接受消息
        一般来说会有别的专门的消息中间件，redis只作为缓存
    如何使用
        subscribe c1 c2 c3 ：一次性订阅多个；可以使用通配符 c*
        publish c2 hello ：消息发布

主从复制
    是什么
        主机数据更新后根据配置和策略，自动同步到备机的master-slave机制，master以写为主，slave以读为主
    主要作用
        读写分离
        容灾恢复
    如何使用
        配从（从机要进行配置）不配主（主机不需要额外配置）
        从库配置：slaveof 主库IP 主库端口
            每次和master断开后要重配，也可以写入配置文件避免频繁配置                

        启动默认是主机，手动配置slaveof变成从机（info replication命令查看）
        主机可以读写，从机只能读（读写分离）
        主机先有数据，从机后连接，可以取得连接之前的数据
        主机进程终止，从机不会竞选新的主机，而是原地等待
        主机恢复后，从机自动重连
        从机进程终止后重新启动配置连接（不能自动连接，默认自己是master，除非配置进conf文件），可以补齐断开时的数据

        常用配置是一主二从模式
        链式主从
            上一个slave可以是下一个slave的master（防止一个主节点多个从节点，降低master的写压力）（此时info replication查看的身份还是slave（依然不可以写））
            中途变更转向会清除之前的数据，重新建立最新拷贝
            slaveof 新主库IP 新主库端口 
        主从身份变化
            主机shotdown（此时从机原地等待）
            从机使用： slaveof no one 命令，自身变回主机

    复制原理
        slave成功连接后会向master发送一个sync命令
        master接收到命令以后启动后台存盘进程，同时收集所有接收到的用于修改数据的命令，在后台执行完以后将整个数据文件发送给slave，以完成一次同步（可以获取连接之前的数据）
        全量复制
            salve在接收到数据库文件数据后，将其存盘并加载到内存（首次全量）
        增量复制
            master继续将新收集到的命令一次传送给slave（后续增量）
        每次重新连接master都会进行一次全量复制

    哨兵模式（sentinel）
        发现master节点失效后，在剩余节点中选举出新的master（反客为主的自动版）
        自定义的sentinel.conf（名字不能错）文件
        配置哨兵监听主库，并设置选举得票条件（一次选举失败会自动重复选举）
        选举出新的master以后，其他slave连接转移
        如果后面发现原master重新连接，那么哨兵会将原master设为一个slave，连接上新的master
        一个哨兵可以监视多个master

    复制的缺点
        master到slave会产生复制延时

copy on write