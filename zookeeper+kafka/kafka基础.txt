
消息队列
    传统消息队列的应用场景
    消息队列的两种模式
        点对点模式（一对一，消费者主动拉去数据，消息收到后消息清除）
            优点
            缺点
        发布/订阅模式（一对多，消费者消费数据后不会清除消息，可以支持多个消费者）
            两种方式：消费者拉取数据；生产者（MQ）推数据
            优点：
                解耦
                削峰
            缺点：
                消费者拉去数据：消费者通过不断轮询消息队列的更新情况来获取数据，如果生产者速度太慢（甚至没有数据），消费者会不停轮询，导致性能资源
                生产者推数据：可能会推数据的速率超过消费者的处理能力

kafka基础架构
    生产者
    kafka集群
        Broker：kafka服务器
        Topic：Topic用于存放不同的数据，是数据的分类（是个逻辑上的概念）
        Partition：分区，提高并发度，增强负载能力。每个Broker实际持有的不一定是一个完整的Topic，可能只是持有一些分区（或者是分区的备份）
        replication：副本。副本的数量（leader也算一个副本）应该小于等于broker的数量（一个节点持有两份副本没有意义），否则在创建topic的时候会报错
        Leader：代表当前分区是主版本。无论是生产者生产数据还是消费者消费数据都是访问leader，follower仅仅起到备份作用
        Follower：代表当前分区是副本
    消费者
        消费者组：
            多个消费者组成消费者组，一个消费者组可以看作一个大的消费者
            可以提高消费能力，增加并发度
            一个分区只能被一个消费者组中的一个成员消费（一个消费者组的的成员不允许重复消费数据，如果想要重复消费数据需要换组）
            由于一个分区只能由一个组内成员消费，所以当组内消费者个数等于订阅的分区数时性能最佳，如果组员个数超过了分区数会造成空等浪费
    zookeeper注册消息
        多个kafka应用只要向同一个zookeeper集群注册，那么就会自动在zookeeper的组织下形程集群
        消费者的消费进度（offset）在版本0.9之前保存在zookeeper中 ，之后保存在本地
            
kafka搭建
    修改server.properties
        broker.id (每个节点不一样，是一个唯一的整数)
        log.dirs：存放kafka中的暂存数据
        log.retention.hours：数据保存的时间（单位小时，默认值168，也就是保存7天的数据）
        log.segment.byte：（暂存文件单个文件（segment）最大的大小，单位字节，默认一个G）
        log.retention.check.interval.ms
        zookeeper.connect=hostname:端口号：配置zookeeper集群（与zookeeper连接，IP+端口号，IP也可以用hostname代替，多组之间逗号隔开）

kafka架构深入
    工作流程
    文件存储机制
        一个Topic（逻辑划分）分为多个Partition（物理划分）
        一个Partition划分为多个segment（segment的大小在配置文件中指定）
        一个Segment对应两个文件
            .log（用来存放实际的数据，不是存放日志）文件
                采用当前segment所包含的第一个message的偏移量来命名
            .index（用于存放偏移量）文件
                两列，第一列存放对应的message索引，第二列存放对应message在.log文件中的起始位置（偏移量）和大小
                索引是递增存放的，因此索引查找时使用二分查找
    
    生产者
        分区原因
            方便扩展，提高负载能力
            以partition为单位读写，提高并发能力
        分区原则
            写数据的时候一定要指明topic
            可以在产生数据的时候指定写入哪个分区
            没有指明分区但是使用了key，会将key的hash值和分区数取余得到使用哪个分区
            没有指明分区也没有使用key，在第一次调用时使用一个随机生成整数（后续使用的时候每次在这个整数上自增），将这个值与topic中可用的的分区数取余（Round-robin算法，其实就是轮询）
        数据可靠性保证
            为了保证数据发送到指定的topic，topic收到信息后会向生产者发送ack。生产者收到ack以后会继续发送数据，否则重发
            何时发送ack：follower和leader同步完成后再发送
                方案一：过半节点同步完成发送
                    优点：延时低
                    缺点：选取新的leader时，容忍n台节点故障，需要2n+1个节点（选举新leader时必须选取有新数据的节点。如果n个节点失效依然还可以不丢失数据，那么持有最新数据的节点只要要n+1个，2n+1个节点中可能只有n+1个持有最新数据，所以集群规模至少需要2n+1）
                方案二：全部同步完成才发送（kafka的实际选择方案，但是做了优化）
                    优点：，选取新leader时，容忍n台节点故障，只需要n+1个节点（只要不是所有节点都失效，就可以从中恢复）
                    缺点：延时高；如果有节点发生故障，会持续不能发送ack
            ISR，in-sync replica set，同步副本（kafka对方案二的优化）
                leader维护了一个动态ISR（同步副本集合），意思是和leader保持同步的副本集合。
                当ISR中的follower完成数据同步后就发送ack
                如果有一个follower长时间未发送数据，那么就会被剔除出ISR，时间阈值可以手动修改
                leader发生故障后，会从ISR的剩余节点中选取新的leader 
                ack应答机制
                    由于对数据的安全性和完整性要求不同，kafka通过使用不同的ack值来表示安全级别
                    参数acks
                        0：生产者不需要等待topic的响应，具有最低延时，但是leader出现故障可能丢数据
                        1：只等待leader写完后就返回ack，不等待follower，如果follower同步之前leader出现故障，那么会出现数据丢失
                        -1（all）：等待ISR中的follower全部写完再返回ack，如果follower复制完成之后，ack返回之前，leader发生故障，可能出现数据重复
                消费一致性问题
                    假设：主节点offset是10，一个副本是8，另一个副本是9。如果主节点发生故障，选取了offset为8的节点，那么从9那里读数据可能会出现数据不一致的问题
                    解决方案：
                        index文件中为每个副本记录两个值。LEO（Log End Offset），表示当前副本的最大偏移量（结尾）；HW（High WaterMark），高水位，表示该partition的所有副本当中，最短的那个副本做对应的offset（最短的那个副本LEO和HW重合，其他的副本中HW在LEO前面）
                        消费者不论从哪个副本读取数据，都只能读取HW之前的，这就保证了消费者所读取到的数据的一致性
                    HW和ack结合使用可以保证数据安全
            follower发生故障：直接从ISR中剔除出去，直到恢复以后再去恢复数据（读取故障前的HW，把HW之后的数据截掉（因为无法感知其他节点的数据情况，只能保证HW之前的数据是安全的），从HW开始向leader进行同步。等待follower的LWO大于等于leader的HW之后（视为追上），如果满足条件，即可重新加入ISR）
            leader发生故障：会从ISR中重新选取新的leader，新leader和其他follower会把HW之后的数据截掉（如果ISR同时全部故障，比如当ISR中只存在leader时可能容易发生，就有丢失数据的风险）
        At least once（至少一次）
            ack设置成-1可以保证不丢失数据，但是可能造成数据重复
        At most once（最多一次）
            ack设置成0可以保证数据最多发送一次
        Exactly once（精准一次） 
            重要信息要求既不丢失也不重复
            幂等性
                数学上指：对应一个函数，一个给定的变量输出的结果和变量本身的值相同，即f(x)=x，因此无论对x使用多少次f，值都不变
                指无论发送多少次重复数据，server端都只会持久化一条。
                kafka对幂等性的实现
                    enable.idompotence=true，将幂等性的使能设置为true（会使得ack默认变成-1）
                    kafka会给每个生产者（producer）每次运行的时候分配一个PID，生产者往同一个分区发数据的时候同时会生成一个SeqNumber一起发送，PID和SeqNumber就构成了一个主键。broker会对这个主键做缓存，当有相同主键的消息提交的时候，broker只会持久化一条
                    如果producer重启，PID会变化，同时不同的分区也具有不同的主键，所以幂等性无法解决跨分区会话的精准一次性。
            At least once + 幂等性 = Exactly once
        生产者小结
            ack应答机制
                0：生产者不需要等待topic的响应，具有最低延时，但是leader出现故障可能丢数据
                1：只等待leader写完后就返回ack，不等待follower，如果follower同步之前leader出现故障，那么会出现数据丢失
                -1（all）：等待ISR中的follower全部写完再返回ack，如果follower复制完成之后，ack返回之前，leader发生故障，可能出现数据重复

    消费者
        消费方式
            消费者采用拉取模式（pull）
                当kafka中没有数据的时候可能会出现空轮询。针对这个情况，kafka的消费者会在消费数据时传入一个时长参数，如果当前一段时间没有数据可以消费，则等待一段时间之后再返回空值
        分区分配策略
            RoundRobin（轮询）
                把Topic中的分区按顺序挨个分配给消费者
                当消费者组订阅了多个Topic以后，把多个topic看作一个大的topic，里面的分区组合起来分配
                    好处是消费者的负担均匀，消费的分区数量最多相差1个
                    当消费者组中的消费者订阅的具体topic不一致的时候此种方法会出问题，导致访问到了错误数据，以及数据不完整的问题。
                    因此想要使用这种方法，就必须保证消费者组内部的消费者订阅的topic是一致的
                    因此轮询不是默认方法
            Range（范围）（默认方法）
                按照单个主题划分的，不进行主题的组合
                把每个主题中的分区，（尽量均匀的）分配给订阅了该主题的消费者
                可能会导致消费者之间的负载不均衡
            分区分配策略的触发条件
                添加和减少消费者组内的消费者个数时
        offset的维护
            因为消费者可能会故障，当恢复后需要从故障位置继续消费，因此需要记录到消费到了哪个offset
            维护工作是由消费者组保存的（不是由单个消费者保存的，如果单个消费者故障，组内别的成员无法获取他的进度继续完成任务）
            组（group）+主题（topic）+分区（partition）唯一确定offset
            消费者组的offset保存在两个地方：
                zookeeper：/consumers目录下保存了消费者组的信息/consumer/消费者组名/topic名/分区
                本地：保存在_consumer_offset

    kafka高效读写数据            
        顺序写磁盘
        零拷贝技术
        分布式
    
    zookeeper在kafka中的作用

    Kafka事务
        之前的PID+分区+SeqNumber只能保证在单次会话中的Exactly Once，当生产者故障重启后可能会导致数据重复
        producer事务
            为了实现跨分区和跨会话的事务，需要引入全局唯一的Transaction ID，并且将会话中获得的PID和Transaction ID和PID绑定
            kafka中引入了一个新的组件 Transaction Coordinator，生产者和这个组件交互获得Transaction ID，并且这个Transaction ID会被kafka自动写入内部的一个topic，使得服务重启后也可以进行状态恢复
        consumer事务
            消费者事务不一定能保证信息被精准消费，比如消费的信息所处的segment过期而消费者事务没有完成需要重读，就会出现数据丢失的情况。（本质上还是消费者高度解耦）

生产者消息发送流程
    生产者采用异步发送，消息发送不需要等待broker返回ack，会继续发出
    如果某条消息发出后在给定的时间阈值内没有收到ack，那么该消息会重发（也就是说ack机制不保证消息的有序性，只是用作保证消息不丢失）
    线程互动
        main线程
            生成数据->交付给Interceptor（拦截器，用于过滤数据）->交付给Serializer（序列化器，进行序列化，kafka中的消息是序列化的）->Partitioner（分区器，用来确定去往哪个分区）
            拦截器和分区器是可自定义的
        经过分区器以后按分区交付给RecordAccumulator
        Sender线程
            Sender线程从RecordAccumulator中按分区获取数据交付给kafka
            取数据的单位是批（batch），只有数据积累到batch.size以后，sender才会发送数据


拦截器
    拦截器可以对输入的消息做任何操作（除了过滤以外，还可以添加字段）
    一般不去改变topic和已选定的分区消息
    返回的消息类型和输入的消息类型是一致的
    一个拦截器可以把输出交给另一个拦截器，形程拦截器链





 

